{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf, erfc, gamma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/data_CMS/cms/vernazza/electrons/'\n",
    "fname = dirname + 'ntuple_435.root'\n",
    "key='rechitntupler/hits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = [u'rechit_chip', 'rechit_module', 'rechit_channel',\n",
    "                u'rechit_energy', 'rechit_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttree = uproot.open(fname)[key]\n",
    "df = ttree.pandas.df(branches, entrystop=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(level=1,drop=True)\n",
    "df.index.names = ['event']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to study the reconstructed energy deposit in the HGCAL prototype. First of all, we want to create the energy distribution: for a given run (let's say the `435` we are considering here), we reconstruct the energy deposit as the sum of all the `rechit_energy` in a given `event`. It is important to note that this is a first order approximation of the true shower energy, as no clustering is applied and no correction for energy losses or leakage is taken into account. Here we use `groupby` to create the sum of the `rechit_energy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esum = df.groupby('event').rechit_energy.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, <font color='green'>plot the histogram of the energy sum distribution</font>. Adjust the binning properly so that you can clearly see the distribution around the peak. Is there any observation you can do about the distribution you are looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram with proper binning, use histtype = 'step' and color = 'k'\n",
    "plt.xlabel('Reco energy [MIP]')\n",
    "plt.ylabel('Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with electromagnetic showers, we should expect the EE part of HGCAL to fully contain the energy deposit. In principle, any energy deposit in the FH layers is either noise or hadrons' contamination to the positrons beam. <font color='green'>Create the energy sum distribution for EE only and compare with the previous one</font>. Plot the two hisograms together (remember to normalize, `density = True` option) and compare them. Do you see any difference? Later in the exercises you will be asked to create this distribution for all the beam energies: also in that case you can check the differences between using the full detector or only the electromagnetic compartment to reconstruct the energy deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, A, sigma, mu):\n",
    "    return A/(sigma * np.sqrt(2 * np.pi))*np.exp( - (x - mu)**2 / (2 * sigma**2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the energy resolution of the calorimeter, we need to reconctruct the energy deposit distribution and extract its mean energy and standard deviation. In the ideal case of no energy losses and with a full containment of the shower, we would expect an energy spectrum peaking around the true beam energy and with a gaussian shape. In our case, as observed above, we have a small left tail, but the distribution is approximately gaussian. In the previous cell, we have defined our gaussian function, used here below to fit the energy sum distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins = np.histogram(esum, bins = np.linspace(0,30000,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_c = (bins[:-1]+bins[1:])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the histogram, we define the bin centers (**note**: remember that the `np.histogram()` method returns the bins edges and not the bin centers) and we use `curve_fit` to fit the energy sums distribution. In this case we use `p0` to set an initial guess for the fit parameters. More precisely: we use the max bin counts (normalisation constant), the standard deviation and the median of the bins' centers distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(gaussian, bins_c, n, p0 = [n.max(), np.std(bins_c), np.median(bins_c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plt.hist(esum, density = True, bins = np.linspace(0,30000,300), color = 'k', histtype = 'step')\n",
    "plt.plot(np.linspace(0,30000,300), gaussian(np.linspace(0,30000,300), *popt), '-')\n",
    "plt.xlabel('Reco energy [MIP]')\n",
    "plt.ylabel('Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'> Which is the value of the fit parameters and of their associated uncertainty? </font> In the final analysis we might want to exclude the left tail from the overall fit not to bias the results. <font color = 'green'>Repeat the gaussian fit above using the EE distribution you have created and using an asymmetric interval for the fit. Let's say from 1.0$\\sigma$ to 2.5$\\sigma$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `dirname` folder you can find the files for all the other beam energies. For each dataset:\n",
    " * Open the file as a pandas `df`;\n",
    " * Create the energy sum distributions (use EE only);\n",
    " * Fit all the distributions with a gaussian around the core and extract the fit parameters;\n",
    " * Plot the $\\mu$ parameter from the fits vs the true beam energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = np.array([20, 30, 50, 80, 100, 120, 150, 200, 250, 300])\n",
    "runs = {\n",
    "    20:  455,\n",
    "    30:  596,\n",
    "    50:  458,\n",
    "    80:  469,\n",
    "    100: 490,\n",
    "    120: 620,\n",
    "    150: 494,\n",
    "    200: 664,\n",
    "    250: 653,\n",
    "    300: 435\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
